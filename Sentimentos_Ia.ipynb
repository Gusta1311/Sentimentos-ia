{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gusta1311/Sentimentos-ia/blob/main/Sentimentos_Ia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO3lLH1iSsNK"
      },
      "outputs": [],
      "source": [
        "!pip install nltk tweepy transformers torch pandas matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKwr9QpPhenp"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "modelo_tweeteval = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_tweeteval)\n",
        "modelo = AutoModelForSequenceClassification.from_pretrained(modelo_tweeteval)\n",
        "print(\"Modelo carregado com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4rXqc7ghxkz"
      },
      "outputs": [],
      "source": [
        "!pip install scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAKyuuZtp0WR"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')  # Faz o download das stopwords corretamente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uZQ3N1Op3Co"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords_pt = set(stopwords.words('portuguese'))\n",
        "print(stopwords_pt)  # Deve exibir a lista de palavras comuns do português\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sZHJC7Sp7ZA"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords', download_dir='/usr/local/nltk_data')\n",
        "\n",
        "# Configurar o NLTK para usar o caminho correto\n",
        "nltk.data.path.append('/usr/local/nltk_data')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BMPLS3f0Wq8I"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import tweepy #pegar os tweets\n",
        "import torch #para ia\n",
        "import nltk #para identificação das palavras e separa e excluir palavras inuteis\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from scipy.special import softmax\n",
        "\n",
        "#baixar stopwords do nltk\n",
        "nltk.download('stopwords')\n",
        "stopwords_pt = set (stopwords.words('portuguese'))\n",
        "\n",
        "#Configurar chaves de API do twitter\n",
        "consumer_key = 'jMt5BARwMdBjXHxW7pGKYlu2t'\n",
        "consumer_secret = '0yp9IanVEvqrYpYH6DLRgHjqaVcykcFYhYKmVeJFnbWmMOak0S'\n",
        "access_token = '1315486843304054785-bjlRmNUNsnKdR9QTZjL7svY26A6Y7c'\n",
        "access_token_secret = 'ZAgVwdiKk7Ewqbk0ebDOncqOLaU9OLU1UQiiXXKJZZOoA'\n",
        "\n",
        "#Autenticação do twitter\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "#modelo pré-treinado do tweet eval\n",
        "modelo_tweeteval = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_tweeteval)\n",
        "modelo = AutoModelForSequenceClassification.from_pretrained(modelo_tweeteval)\n",
        "def limpar_texto(texto):\n",
        "    texto = texto.lower()  # Converter para minúsculas\n",
        "    texto = re.sub(r\"http\\S+\", \"\", texto)  # Remover links\n",
        "    texto = re.sub(r\"@\\w+\", \"\", texto)  # Remover menções\n",
        "    texto = re.sub(r\"[^a-zA-Zá-úÁ-Ú ]\", \"\", texto)  # Remover caracteres especiais\n",
        "    palavras = texto.split()\n",
        "    palavras = [p for p in palavras if p not in stopwords_pt]  # Remover stopwords\n",
        "    return \" \".join(palavras)\n",
        "\n",
        "#Função para classificar sentimento\n",
        "def classificar_sentimento(texto):\n",
        "    tokens = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        resultado = modelo(**tokens)\n",
        "\n",
        "    #Convrter logits para probabilidade\n",
        "    pontuacoes = resultado.logits[0].numpy()\n",
        "    probabilidades = softmax(pontuacoes)\n",
        "\n",
        "    categorias = [\"Negativo\", \"Neutro\", \"Positivo\"]\n",
        "    indice = probabilidades.argmax()\n",
        "\n",
        "    return categorias[indice], probabilidades\n",
        "\n",
        " #Escolher entre manual ou analise de tweets\n",
        "print(\"Ecolha uma opção:\")\n",
        "print(\"1 - Digitar frases manualmente\")\n",
        "print(\"2 - Analisar tweets de um perfil\")\n",
        "print(\"3 - Analisar um tweet sobre um assunto\")\n",
        "\n",
        "opcao = input (\"Digite o numero da opcao desejada: \")\n",
        "\n",
        "dados = []\n",
        "\n",
        "if opcao == \"1\":\n",
        "    while True:\n",
        "        frase = input(\"\\nDigite uma frase (ou 'sair' para encerrar): \")\n",
        "        if frase.lower() == \"sair\":\n",
        "            break\n",
        "        sentimento, probabilidades = classificar_sentimento(frase)\n",
        "        print(f\"Sentimento: {sentimento} | Probabilidades: {probabilidades}\\n\")\n",
        "        dados.append({\"Texto\": frase, \"Sentimento\": sentimento, \"Probabilidades\": probabilidades})\n",
        "elif opcao == \"2\":\n",
        "    perfil = input(\"\\nDigite o @ do perfil do Twitter (sem o '@'): \")\n",
        "    tweets = api.user_timeline(screen_name=perfil, count=10, tweet_mode=\"extended\")\n",
        "\n",
        "    for tweet in tweets:\n",
        "        texto_limpo = limpar_texto(tweet.full_text)\n",
        "        sentimento, probabilidades = classificar_sentimento(texto_limpo)\n",
        "        dados.append({\"Texto\": tweet.full_text, \"Sentimento\": sentimento, \"Probabilidades\": probabilidades})\n",
        "\n",
        "elif opcao == \"3\":\n",
        "    termo_pesquisa = input(\"\\nDigite um termo para buscar no Twitter: \")\n",
        "    tweets = api.search_tweets(q=termo_pesquisa, lang=\"pt\", count=10)\n",
        "\n",
        "    for tweet in tweets:\n",
        "        texto_limpo = limpar_texto(tweet.text)\n",
        "        sentimento, probabilidades = classificar_sentimento(texto_limpo)\n",
        "        dados.append({\"Texto\": tweet.text, \"Sentimento\": sentimento, \"Probabilidades\": probabilidades})\n",
        "\n",
        "else:\n",
        "    print(\"Opção inválida. Saindo do programa.\")\n",
        "    exit()\n",
        "\n",
        "#Criar DataFrame\n",
        "df = pd.DataFrame(dados)\n",
        "\n",
        "#Exibir frases/tweets analisados\n",
        "print(df)\n",
        "\n",
        "#Cria gráfico de barras se houver dados\n",
        "if not df.empty:\n",
        "  contagem_sentimentos = df[\"Sentimento\"].value_counts()\n",
        "\n",
        "  plt.figure(figsize=(6,4))\n",
        "  contagem_sentimentos.plot(kind=\"bar\", color=[\"red\", \"gray\", \"green\"])\n",
        "  plt.title(\"Análise de Sentimentos\")\n",
        "  plt.xlabel(\"Sentimento\")\n",
        "  plt.ylabel(\"Quantidade\")\n",
        "  plt.xticks(rotation=0)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}